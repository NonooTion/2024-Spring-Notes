# 操作系统概念

> NonoTion笔记

## 第二章 操作系统结构

### 2.1 操作系统的服务



# 第二部分 进程管理

## 第三章 进程

现代计算机系统允许加载多个程序到内存，以便并发执行。这种改进要求：对各种程序提供更严的控制和更好的划分。这些需求就导致了`进程`(process)概念的诞生

### 3.1.进程概念

#### 3.1.1 进程

进程代表了计算机上一个运行中的程序实例，它包括以下组成部分：

- 程序代码，有时也称为`文本段`(text section)或`代码段`(code section)
- 当前活动，如`程序计数器`(program counter)的值和处理器寄存器的内容等
- 进程`堆栈`(stack) 包括临时数据。如函数参数，返回地址和局部变量
- `数据段`(data section)包括全局变量
- `堆`(heap) 进程运行时分配的内存

需要区分的是：程序本身不是进程。程序是被动实体，如存储在磁盘上包含一系列指令的文件，通常称为`可执行文件`(executable file)。相反，进程是活动实体，具有一个程序计数器用于表示下个执行命令和一组相关资源。

当一个可执行文件被加载到内存时，这个程序就称为进程

程序和进程不是一一对应的，比如一个用户可以调用Web浏览器的多个副本，虽然代码段相同，但是数据，堆及堆栈段却不同

进程本身也可作为一个环境，用于执行其他代码(java编程环境)

#### 3.1.2 进程状态

进程在运行时会改变**状态**。

每个进程可能会处于以下状态：

![](image/%E8%BF%9B%E7%A8%8B%E7%8A%B6%E6%80%81.png)

- new：进程正在被创建
- running：指令正在执行
- waiting：进程等待发生某个事件
- ready：进程等待分配处理器
- terminated：进程已经完成执行

#### 3.1.3 进程控制块

进程在操作系统中，被`进程控制块`(process control block)来表示。（也称为`任务控制块` task control block)

![](image/%E8%BF%9B%E7%A8%8B%E6%8E%A7%E5%88%B6%E5%9D%97.png)

进程控制块包含许多个于某个特定进程相关的信息：

- 进程状态(process status)：状态可以包括new，ready，running，waiting，terminated
- 程序计数器：计数器表示进程将要执行的下个指令的地址
- CPU寄存器(CPU register)：保存包括累加器、索引寄存器、堆栈指针、通用寄存器和其他条件码信息寄存器的状态信息。以便进程以后能够正确地执行

![](image/%E8%BF%9B%E7%A8%8B%E4%B9%8B%E9%97%B4%E7%9A%84CPU%E5%88%87%E6%8D%A2.png)

- 内存管理信息(memory-management information)：这类信息可以包括基地址和界限寄存器的值，页表或者段表
- 记账信息(accouting information)：包括CPU信息，实际使用时间，时间期限，记账数据，作业或进程数量
- I/O状态信息(I/O status information)：这类信息包括分配给进程的I/O设备列表、打开文件列表

总而言之，PCB简单地作为这些信息的仓库，这些信息随着进程的不同而不同

#### 3.1.4 线程

上面我们讨论的进程模型暗示：每个进程是一个只能进行单个执行`线程`(Thread)的程序。

许多现代操作系统扩展了进程概念，以便支持一次能够执行多个线程。在支持线程的系统中，PCB被扩展到包括每个线程的信息。为了实现线程，系统还需要一些改变，我们将在第四章讨论线程

### 3.2 进程调度

**进程调度**是操作系统中的一种关键机制，用于决定何时运行哪个进程。它负责有效地分配CPU资源，以满足不同进程的需求。

**进程调度器**(process scheduler)选择一个可用进程(可能从多个可用进程集合中)到CPU上执行

#### 3.2.1 调度队列

`作业队列`(job queue)：进程在进入系统时，会被加到作业队列，这个队列包括操作系统在内的所有进程。

驻留在内存中的、就绪的、等待运行的进程保存在`就绪队列`(ready queue)上

`设备队列`(device queue)：等待特定I/O设备的进程列表，每个设备都有自己的设备队列

![](image/%E5%B0%B1%E7%BB%AA%E9%98%9F%E5%88%97%E5%92%8C%E5%90%84%E7%A7%8D%E8%AE%BE%E5%A4%87%E9%98%9F%E5%88%97.png)

进程在不同的队列之间"迁移"

进程调度通常使用队列图(queueing diagram)来表示

![](image/%E8%BF%9B%E7%A8%8B%E8%B0%83%E5%BA%A6%E9%98%9F%E5%88%97%E5%9B%BE.png)

最初，新进程被加到就绪队列；它在就绪队列中等待，直到被选中执行或者被`分派`(dispatched)

当该进程被分配到CPU并执行时，以下事件可能发生：

- 进程发出I/O请求，并被放到I/O队列
- 进程可能创建一个新的子进程，并等待终止
- 进程可能由于中断而被强制释放CPU，并被放回就绪队列

对于前面两种情况，进程最终会从等待状态切换到就绪状态，并放回就绪队列。进程重复这一循环直到终止；然后它会从所有队列中删除，其PCB和资源也被释放

#### 3.2.2 调度程序

进程在整个生命周期中，会在各种调度队列之间迁移。操作系统为了调度必须按一定的方法从这些队列中选择进程。进程选择通过适当`调度器`或`调度程序`(scheduler)来执行



对于批处理系统，当提交的进程大于可以立即执行的，这些进程会被保存到大容量存储设备(通常为磁盘)的缓冲池，以便以后执行。

`长期调度程序`(long-term scheduler)或`作业调度程序`(job scheduler)从该池中选择进程，加到内存，以便执行

`短期调度程序`(short-term scheduler)或`CPU调度程序`(CPU scheduler)从准备执行的进程中选择进程，并分配CPU

这两种调度程序的区别是执行频率。

短期调度程序必须经常为CPU选择新的进程。进程可能执行几毫秒就会等待I/O请求。

长期调度程序执行得并不频繁，在新进程的创建之间，可能有几分钟间隔，长期调度程序控制多道程序程度。

大多数进程可被描述为:

- `I/O密集型进程`(I/O-bound process) 执行I/O比执行计算花费更多时间
- `CPU密集型进程`(CPU-bound process) 很少产生I/O请求，而是将更多的时间用于执行计算

长期调度程序应该选择I/O密集型和CPU密集型的合理进程组合



有的操作系统，如分时操作系统，可能会引入一个额外的`中期调度程序`(medium-term scheduler)，其核心思想是可将进程从内存(或CPU竞争)中移出，从而降低`多道程序程度`(degree of multiprogramming,内存中进程的数量)。

![](image/%E6%B7%BB%E5%8A%A0%E4%B8%AD%E7%BA%A7%E8%BF%9B%E7%A8%8B%E8%B0%83%E5%BA%A6%E5%88%B0%E9%98%9F%E5%88%97%E5%9B%BE.png)

这种方案称为`交换`(swap)。通过中期的调度程序，进程可`换出`(swap out)，并在后来可`换入`(swap in)为了改善进程组合，或者由于内存需求改变导致过度使用内存从而需要释放内存，就有必要使用交换 第八章会讨论这个问题

#### 3.2.3 上下文切换

中断导致CPU从执行当前任务改变到执行内核程序。这种操作在通用系统种经常发生。当中断发生时，系统需要保存当前运行在CPU上的进程的上下文，以便在处理后能够恢复上下文，即先挂起进程，再恢复进程。进程上下文采用进程PCB表示。通常执行`状态保存`(state save)，保存CPU当前状态(包括内核模式和用户模式);之后 `状态恢复`(state restore)重新开始运行



上下文切换的时间是纯粹的开销，因为在切换时系统并没有做任何有用的工作

上下文切换的时间取决于硬件支持

### 3.3 进程运行

大多数系统的进程能够并发执行，它们可以动态创建和删除。因此操作系统必须提供机制，以创建进程和终止进程

#### 3.3.1 进程的创建

进程在执行过程种可能创建多个新的进程，创建进程称为父进程，新的进程称为子进程。每个新进程可以再创建其他进程，从而形成`进程树`(process tree)

![](image/%E8%BF%9B%E7%A8%8B%E6%A0%91.png)

大多数的操作系统对进程的识别采用的是唯一的`进程标识符`(process identifier,pid)，这通常是一个整数值

当一个进程创建子进程时，该子进程会需要一定的资源(CPU时间、内存、文件、I/O设备等)来完成任务。**子进程可以从操作系统哪里直接获得资源，也可以只从父进程那里获得资源子集**。父进程可能要在子进程之间分配资源或共享资源(如内存和文件)。**限制子进程只能使用父进程的资源，可以防止创建过多进程，导致系统超载**



当进程创建新进程时，可能有两种执行可能：

- 父进程和子进程并发执行
- 父进程等待，直到某个或全部子进程执行完

新进程的地址空间也有两种可能：

- 子进程是父进程的复制品(它具有与父进程相同的程序和数据)
- 子进程加载另一个程序

Unix Example

```c
int main()
{
	pid_t  pid;
	/* fork another process */
	pid = fork();
	if (pid < 0) { /* error occurred */
		fprintf(stderr, "Fork Failed");
		exit(-1);
	}
	else if (pid == 0) { /* child process */
		execlp("/bin/ls", "ls", NULL);
	}
	else { /* parent process */
		/* parent will wait for the child to complete */
		wait (NULL);
		printf ("Child Complete");
		exit(0);
	}
}
```



通过系统调用fork()可以创建新进程，新进程的地址空间复制了原来进程的地址空间。这种机制允许父进程和子进程之间轻松通信。对于子进程fork()的返回值为0，而父进程的返回值大于0

![](image/%E9%80%9A%E8%BF%87%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8fork%E5%88%9B%E5%BB%BA%E8%BF%9B%E7%A8%8B.png)

在fork系统调用后，子进程使用系统调用exec()，加载二进制文件到内存中(破坏了包含系统调用exec()的原来程序的内存内容)，并开始执行

而父进程则调用wait()系统调用，把自己移出就绪队列，直到子进程终止

#### 3.3.2 进程终止

当进程完成执行最后语句并且通过系统调用exit()请求操作系统删除自身时，进程终止。

此时进程可以返回状态值(通常为整数)到父进程(通过系统调用wait())。所有进程资源都会由操作系统释放



进程通过适当系统调用，可以终止另一进程。通常只有终止进程的父进程可以执行这一系统调用，如果要终止子进程，则父进程需要知道这些子进程的标识符，因此当一个新进程创建时，新创建进程的标识符要传递到父进程



父进程终止子进程的原因：

- 子进程使用了超过它所分配的资源
- 分配给子进程的任务不再需要
- 父进程正在退出，且操作系统不允许无父进程的子进程继续执行

有些系统不允许子进程在父进程已经终止的情况下存在。对于这类系统，如果一个进程终止，那么它的所有子进程也应终止，这种现象叫做`级联终止`(cascade termination)



父进程可以通过wait()系统调用等待子进程终止。系统调用wait()可以通过参数，让父进程获得子进程的退出状态



当一个进程终止时，操作系统会释放其资源。不过它位于进程表中的条目还存在，直到它的父进程调用wait()，这是因为进程表包含了进程的退出状态。当进程已经终止，但是其父进程尚未调用wait()，这样的进程称为`僵尸进程`(zombie process)

一般而言僵尸进程只会短暂存在，一旦父进程调用了wait()，僵尸进程的进程标识符和他在进程表中的条目就会释放

如果父进程没有调用wait()就终止，子进程会变为`孤儿进程`(orphan process)

此时,Linux和UNIX将init进程作为孤儿进程的父进程



### 3.4 进程间通信

操作系统内的并发执行进程可以是独立的或也可以是协作的

如果一个进程不能影响其他经常或受其他进程影响，那么该进程是独立的

如果一个进程能影响其他进程或受其他进程影响，那么该进程是协作的



为什么要提供环境允许进程协作?

- 信息共享：多个用户可能对同样的信息感兴趣，所以应该提供环境允许并发访问这些信息
- 计算加速：如果希望一个特定任务快速运行，那么应将它分成子任务，而每个子任务可以与其他子任务一起并发执行
- 模块化：按模块化的方式构造系统，将一个系统分为多个子系统
- 方便：即使单个用户也可能同时执行许多任务

协作进程需要有一种`进程间通信`(InterProcess Communication，IPC)机制，以允许进程相互交换数据与信息。

进程间通信的两种基本模型：

`共享内存`(shared memory)：建立起一块供协作进程共享的内存区域，经常通过向此共享区域读出或写入数据来交换信息。

`消息传递`(message passing)：在协作进程间交换消息来实现通信

![](image/%E9%80%9A%E4%BF%A1%E6%A8%A1%E5%9E%8B.png)

消息传递：对交换较少数量的数据很有用，无需避免冲突。对于分布式系统易于实现

共享内存：比消息传递更快，一但建立共享内存区，所有访问都可作为常规内存访问，无需借助内核



#### 3.4.1 共享内存系统

采用共享内存的进程间通信，需要通信进程建立共享内存区域。通常一片共享内存区域驻留在创建共享内存段的进程地址空间内。其他希望使用这个共享内存段进行通信的进程应将其附加到自己的地址空间

#### 3.4.2 消息传递系统

消息传递为进程提供了一种通信和同步其操作的机制，而无需求助于共享变量。
在分布式环境中特别有用。

消息传递功能提供两种操作:

- send(message) 
- receive(message)

如果进程P和Q需要进行通信，那么它们之间需要建立**通信链路**，通过send/receive收发消息

几个方法用于逻辑实现链路和操作send()/receive():

- 直接或间接的通信
- 同步或异步的通信
- 自动或显示的缓冲

##### 3.4.2.1 命名

**直接通信**

需要通信的每个进程必须明确指定通信的接收方或发送方，采用这种方案，原语send()和receive()定义如下

- send(P,message)：向进程P发送message
- receive(Q,message)：从进程Q接收message

这种方案下的通信链路具有以下属性:

- 在通信的每对进程之间，自动建立链路
- 每个链路只与两个进程相关
- 每对进程之间只有一个链路

**间接通信**

通过邮箱或端口来发送或接收消息

邮箱可以抽象为一个对象，进程可以向其中存放消息，也可以从中删除消息，每个邮箱都有一个唯一的标识符。

一个进程可以通过多个不同的邮箱与另一个进程通信,但两个进程间只有拥有一个共享邮箱时才能通信

操作系统提供机制允许进程进行操作:

- 创建新的邮箱
- 通过邮箱发送或接收消息
- 删除邮箱

原语send()和receive()定义如下

- send(A,message)：向邮箱A发送message
- receive(A,message)：从邮箱A接收message

这种方案下的通信链路具有以下属性:

- 只有两个进程共享一个邮箱时，才能建立通信链路
- 一个链路可以与两个或更多进程相关联
- 两个通信进程之间可以有多个不同链路，每个链路对应一个邮箱

##### 3.4.2.2 同步

消息传递可以是阻塞的或非阻塞的，也成为同步和或异步的

- 阻塞发送：发送进程阻塞，直到消息由接收进程或邮箱接收
- 非阻塞发送：发送进程发送消息，并恢复操作
- 阻塞接收：接收进程阻塞，直到有消息可用
- 非阻塞接收：接收进程收到一个有效消息或空消息

##### 3.4.2.3 缓存

不论通信是直接的还是间接的，通信进程交换的消息总是驻留在临时队列中。简单地讲，队列实现有三种方法：

- 零容量：队列的最大长度为0，链路中不能有任何消息处于等待。发送者应该阻塞，直到接收者收到消息
- 有限容量-有限长度的n条消息如果链路满，发送方必须等待
- 无限容量-无限长度发送方从不等待

## 第四章 多线程编程

第3章讨论的进程模型假设每个进程具有单个控制线程的一个执行程序。几乎所有现代操作系统都允许一个进程包含多个线程

### 4.1 概述

![](image/%E5%8D%95%E7%BA%BF%E7%A8%8B%E8%BF%9B%E7%A8%8B%E5%92%8C%E5%A4%9A%E7%BA%BF%E7%A8%8B%E8%BF%9B%E7%A8%8B.png)

每个线程是CPU使用的一个基本单元；它包括线程ID，程序计数器，寄存器组和堆栈。它与同一进程的其他线程共享代码段、数据段和其他操作系统资源。

如果一个进程具有多个控制线程，那么他能同时执行多个任务

#### 4.1.1 动机

现代计算机运行的大多数应用软件都是多线程的。一个应用程序通常作为具有多个控制线程的一个进程来实现。

#### 4.1.2 优点

- `响应性`(Responsiveness)：如果一个交互式程序采用多线程，那么即使部分阻塞或执行冗长操作，它仍可以继续执行，从而增加对用户的响应程度。
- `资源共享`(Resource Sharing)：线程默认共享它们所属进程的内存和数据。代码和数据共享的优点是：它允许一个应用程序在同一地址空间内有多个不同活动线程
- `经济`(Economy)：进程创建所需要的内存和资源分配十分昂贵。由于线程能够共享它们所属进程的资源，所以创建和切换线程更加经济
- `可伸缩性`(Utilization of MP Architecture)
- 对于多处理器体系结构，多线程的优点更大，因为线程可以在多处理核上并行运行



## 第六章 进程同步

`协作进程`(cooperating process)能与系统内的其他执行进程相互影响。它能通过共享逻辑地址空间(即代码和数据)或通过文件或消息来共享数据。

前一种情况通过线程来实现。

共享数据的并发访问可能会导致数据的不一致问题，**本章讨论多种机制，以便确保共享同一逻辑地址空间的协作进程的有序执行，从而维护数据的一致性**



### 6.1 背景

`竞争条件`(race condition)多个进程并发访问和操作同一数据并且执行结果与特定访问顺序有关。为了防止竞争条件，需要确保每次只有一个进程可以操纵资源

本章的大部分内容就是：协作进程如何进行`进程同步`(process synchronization)和`进程协调`(process coordination)



### 6.2 临界区问题

`临界区`(critical section) 进程中一段访问共享资源的程序代码，当一个进程在临界区内执行时，其他经常不允许在它们的临界区内执行

`临界区问题`(critical-section problem) 设计一个协议，保证进程之间相互协作

在进入临界区前，每个进程应请求许可，实现该请求的代码称为`进入区`(entry section)。临界区之后可以有`退出区`(exit section),其他代码为`剩余区`(remainder section)



临界区问题的解决方案应该满足下面**三个要求**:

1. `互斥`(mutual exclusion):如果进程pi在其临界区内执行，那么其他进程都不能在其临界区内执行
2. `进步`(progress)：如果没有进程在其临界区内执行，并且有进程需要进入临界区，那么只有那些不在剩余区内执行的进程可以参加选择，以便确定谁能下次进入临界区，并且这种选择不能无限推迟

3. `有限等待`(bounded waiting)：从一个进程做出进入临界区的请求直到这个请求允许为止，其他进程允许进入其临界区的次数具有上限



### 6.3 Peterson解决方案

Peterson解决方案适用于两个进程交错执行临界区和剩余区

Peterson解答要求两个进程共享两个数据项

```cpp
int turn;	//变量turn表示哪个进程能够进入临界区
boolean flag[2];	//数组flag表示哪个进程准备进入临界区

do{
    flag[i]=true;
    turn=j;
    while(flag[j]&&turn==j);
    
    //临界区
    
    flag[i]=false;
    
    //剩余区
}while(true)
```



Peterson解决方案的正确性证明

1. 互斥

只有当flag[j]=false或者turn==i时，进程pi才能进入临界区

假设两个进程能够同时在临界区内执行，那么flag[0]=flag[1]=true，但是由于turn不能同时为两个值，所以p0和p1不能同时在临界区内执行

2. 进步

对于Pi来说，只有flag[j]=true且turn==j时，Pi才会陷入while循环，如果Pj不准备进入临界区，即flag[j]=false,那么Pi就不会陷入while循环，可以进入临界区

3. 有限等待

对于进程Pi来说，当Pi执行完临界区代码后，会将flag[i]设为false，此时flag[j]如果准备进入临界区，就会从while循环中跳出，进入临界区



### 6.4 硬件同步

基于软件的解决方案，如6.3提到的Peterson解决方案并不保证在现代计算机体系结构上正确工作

本节介绍一些基于`加锁`(locking)为前提的临界区问题的多个解答



对于单处理器环境，临界区问题可简单地加以解决->修改共享变量时只需要禁止中断出现

但在多处理器环境中，这种解决方案是不可行的



许多现代系统提供特殊硬件指令，用于检测和修改字的内容，或者用于**原子地**(atomically)交换两个字(作为不可中断地指令)



不讨论特定机器的特定指令，通过两个指令抽象这些指令背后的主要概念

指令 test_and_set()

```c
boolean test_and_set(boolean *target)
{
    boolean rv=*target;
    *target=true;
    
    return rv;
}

//采用指令test and set()实现互斥
//声明一个布尔变量lock ,初始化为false

do
{
    while(test_and_set(&lock));
    /*	do nothing	*/
    
    //critical section
    
    lock=false;
    
    // remainder section
} while (true);
```



指令compare and swap()

```c
int compare and swap(int *value,int expected ,int new_value)
{
    int temp=*value;
    
    if(*value==expected) *value=new_value;
    
    return temp;
}

//利用指令compare and swap()的互斥实现

do{
    while(compare_and_swap(&lock,0,1)!=0); 
    //do nothing
    
    //critical section
    
    lock=0;
    
    //remainder section
}while(true);
```



**虽然上面两个算法满足互斥要求，但是并未满足有限等待要求**



另一种基于test_and_set的算法，满足解决临界区方案的三个要求



```c
//共用的数据结构
boolean waiting[n];
boolean lock;

//算法实现
do{
    waiting[i]=true;
    key=true;
    //互斥
    while(waiting[i]&& key)
        key=test_and_set(&lock);
    waiting[i]=false;
    
    //critical section
    
    //每个准备进入临界区的进程最多等待n-1次,满足有限等待
    j=(i+1)%n;
    while((j!=i)&&!waiting[j]) 
        j=(j+1)%n;
    
    //进步
    if(j==i)
        lock=false;
    else
        waiting[j]=false;
    
    //reminder section
}while(true);
```



### 6.5 互斥锁

用于解决临界区问题的，最简单的软件工具就是`互斥锁`(mutex lock)

事实上mutex来源于mutual exclusion

我们使用互斥锁保护临界区，从而防止竞争条件。也就是说，一个进程在进入临界区时应得到锁，退出进程区时释放锁

这两个操作通过函数acquire()获得锁，通过release()释放锁

```c
do
{
    获得锁
        
        关键区
        
    释放区
        
        剩余区
}while(true);
```



acquire()函数与release()函数

```c
acquire()
{
    while(!available);//busy wait 忙等
    available=false;
}

release()
{
    available =true;
}
```

对这两个函数的调用必须原子地执行



这里所给的实现的主要缺点是：它需要`忙等待`(busy waiting)。当一个进程在临界区时，任何其他进程进入临界区时必须连续循环地调用acquire().

这种类型的锁也叫做`自旋锁`(spinlock),因为进程不断地旋转，以等待锁变得可用

忙等待浪费CPU周期，而这原本可以有效地用于其他进程



自旋锁也有一个优点:当进程在等待锁时，没有上下文切换 6.7节会进一步讨论如何使用互斥锁解决经典的问题



### 6.6 信号量

信号量的功能类似于互斥锁，但是它能提供更为高级的方法，以便进程能够同步活动

一个`信号量`(semaphore)S是一个整型变量，它除了初始化外只能通过两个标准原子操作:wait()和signal()来访问



wait()与signal()的定义

```c
wait(S)
{
    while(S<=0);
    //busy wait
    S--;
}

signal(S)
{
    S++;
}
```



#### 6.6.1 信号量的使用

 操作系统通常区分计数信号量与二进制信号量

`计数信号量`(counting semaphore)的值不受限制

`二进制信号量`(binary semaphore)的值只能为0或1

二进制信号量类似于互斥锁，在没有提供互斥锁的系统上，可以使用二进制信号量来提供互斥



当进程需要资源时，需要对该信号进行wait()操作->减少信号量的计数

当进程释放资源时，需要对该信号量执行signal()操作->增加信号量的计数

当信号量的计数为0时，所有资源都在使用中，之后需要使用资源的进程将会阻塞，直到计数大于0



可以使用信号量来解决各种同步问题。

例如：两个并发的进程P1,P2。P1有语句S1，P2有语句S2。要求S1执行后才能执行S2。

解决方案：让P1,P2共享同一信号量synch,并且初始化为0。

```c
//进程P1中
S1;
signal(synch);

//进程P2中
wait(synch);
S2;

```



#### 6.6.2 信号量的实现

6.6.1中描述的信号量操作wait()和signal()具有忙等待的问题。

为了克服忙等待，修改信号量操作wait()和signal()的定义

wait()：当一个进程执行操作wait()并且信号量不为正时，它必须等待。然而该进程并非忙等待，而是阻塞自己。阻塞操作将一个进程放到与信号量相关的等待队列里，并且将该进程状态切换为等待状态。然后控制转到CPU调度程序，以便选择执行另一个进程

被阻塞的进程在其他进程执行signal()之后，应该重新被执行。进程的重新执行是通过操作**wakeup()**来进行的,它将进程从等待状态改为就绪状态，进程被添加到就绪队列



为了实现上面定义的信号量，给出以下定义

```c
typedef struct{
    int value;
    struct process * list;
}semaphore;

wait(semaphore * S)
{
    s->value--;
    if(S->value<0)
    {
        add this process to S->list;
        block();
    }
}

signal(semaphore *S)
{
    s->value++;
    if(s<=0)
    {
        remove a process P from S->list;
        wakeup(P);
    }
}
```



操作block()挂起调用它的进程，操作wakeup(P) 重新启动阻塞进程P的执行。这两个操作都是由操作系统作为基本系统调用来提供的。



这样实现的信号量可以为负数，当信号量为负数时，**它的绝对值代表等待它的进程数**,这种情况的发生是因为在实现wait操作时,互换了递减和测试的顺序



每个信号量包含一个整数和一个PCB链表指针。信号量的正确使用不依赖于信号量链表的特定排队策略

信号量操作应该原子地进行，对于单处理器系统，在执行wait()或signal()时，可以简单禁止中断。而对于多处理器系统，每个处理器的中断都需要禁止。这时很困难的，也很影响性能，所以SMP系统需要提供其他加锁计数，如：compare_and_swap()或者自旋锁，以确保wait()和signal()原子执行



这里定义的wait()和signal()操作并非完全取消忙等待，而是将忙等待移入临界区。wait()和signal()的临界区很短，因此临界区几乎不被占用，忙等待很少发生，而且所需时间很少



#### 6.6.3 死锁和饥饿

具有等待队列的信号量可能会导致两个或多个进程无限等待一个事件，而该事件只能由这些等待进程之一来产生。这里的事件时执行操作signal()，当出现这样的状态时，这些进程就为`死锁`(deadlocked)

我们会在第七章讨论多种解决死锁的机制

与死锁相关的另一个问题时`无限阻塞`(indefinite bolcking)或`饥饿`(starvation)，即进程无限等待信号量。如果对信号量有关链表按FILO顺序来增加和删除进程，可能会导致无限阻塞的问题



#### 6.6.4 优先级的反转

`优先级反转`(priority inversion)：进程调度过程中的一种特殊现象。高优先级进程因为所需资源被低优先级进程占用而被阻塞，占用该资源的低优先级进程因其优先级低于其他进程也无法执行而释放资源，造成最高优先级进程反而在一段时间内无法执行，系统性能下降的情况。

`优先级继承协议`(priority-inheritance protocol)：所有正在访问资源的进程获得需要访问它的更高优先级进程的优先级，直到它们用完了有关资源为止，当它们用完时，它们的优先级恢复到原始值。



### 6.7 经典同步问题

#### 6.7.1 有界缓冲问题

有界缓冲问题，也称为**生产者-消费者问题**，涉及到两个进程共享一个固定大小的缓冲区。这个缓冲区用于存储数据，其中一个进程是**生产者**，负责将信息放入缓冲区；另一个进程是**消费者**，从缓冲区中取出信息。

以下是有界缓冲问题的关键特点：

1. **共享缓冲区**：生产者和消费者共享一个固定大小的缓冲区。
2. **生产者**：将数据放入缓冲区。
3. **消费者**：从缓冲区中取出数据。
4. **互斥访问**：在任何时候，只能有一个生产者或消费者访问缓冲区。
5. 缓冲区状态：
   - 当缓冲区已满时，生产者不会继续添加数据。
   - 当缓冲区为空时，消费者不会从中移走数据。

对于这个问题，生产者和消费者进程共享以下数据结构:

```c
int n;
semaphore mutex=1;  //提供缓冲区的互斥要求
semaphore empty=n;  //表示空的缓冲区数量
semaphore full=0;  //表示满的缓冲区数量
```



生产者进程结构

```c
do{
    ...
    //produce an item in next_produced
    ...
    wait(empty);
    wait(mutex);
    ...
    //add next_produced to the buffer
    ...
    signal(mutex);
    signal(full);
}while(true);
```



消费者进程结构

```c
do{
    wait(full);
    wait(mutex);
    ...
    //remove an item from buffer to next_consumed
    ...
    signal(mutex);
    signal(empty);
    ...
    //consume the item in next_consumed
    ...
}while(true);
```



#### 6.7.2 读者-作者问题

假设一个数据库被多个并发进程共享。有的进程只需要读数据库，称为读者。而有的进程可能需要更新数据库，称为作者。两个或多个读者同时访问数据库，不会有不利的影响。但是一个作者与其他线程同时访问数据库，会导致混乱

我们要求读者在写入数据库时具有共享数据库独占的访问权。这一同步问题称为`读者-作者问题`

第一读者-作者问题：要求读者不应保持等待，除非作者已获得权限使用共享对象

第二读者-作者问题：一旦作者就绪，那么作者会尽可能快地执行。换句话说，如果有一个作者等待访问对象，那么不会有新的读者可以开始读

第一种情况下，作者可能饥饿；第二种情况下，读者可能饥饿

这里介绍第一种解答



读者进程共享以下数据结构

```c
semaphore rw_mutex=1;//供作者作为互斥信号量
semaphore mutex=1;//保证更新read_count时的互斥
in read_count=0;//用于跟踪多少进程正在读对象
```



作者进程的结构

```c
do
{
    wait(rw_mutex);
    ...
    //writing is performed
    ...
    signal(rw_mutex);
}while(true);
```



读者进程的结构

```c
do{
    wait(mutex);
    read_count++;
    if(read_count==1)
        wait(rw_mutex);
    signal(mutex);
    ...
    //reading is performed
    ...
    wait(mutex);
    read_count--;
    if(read_count==0)
        signal(rw_mutex);
    signal(mutex);
}while(true);
```

有些系统将读者-作者问题及其解答进行了抽象，从而提供`读写锁`(read-writer lock)，在获取读写锁时，需要指定锁的模式：读访问或写访问。当一个进程只希望读共享数据时，可申请读模式的读写锁；当一个进程希望修改共享数据时，可以申请写模式的读写锁

读写锁在以下情况特别有用：

- 容易识别哪些进程只读共享数据和哪些经常只写共享数据的应用程序
- 读者进程数比作者进程数多的应用程序。读写锁的建立开销通常大于信号所或互斥锁，这一开销可以允许多个读者的并发程度的增加来加以弥补



#### 6.7.3 哲学家就餐问题

有五个哲学家，他们的生活方式是交替地进行思考和进餐，哲学家们共用一张圆桌，分别坐在周围的五张椅子上，在圆桌上有五个碗和五支筷子，平时哲学家进行思考，饥饿时便试图取其左、右最靠近他的筷子，只有在他拿到两支筷子时才能进餐，该哲学家进餐完毕后，放下左右两只筷子又继续思考。

**约束条件**

(1)只有拿到两只筷子时，哲学家才能吃饭。

(2)如果筷子已被别人拿走，则必须等别人吃完之后才能拿到筷子。

(3)任一哲学家在自己未拿到两只筷子吃完饭前，不会放下手中已经拿到的筷子。



共享数据

```c
semaphore chopstick[5];//所有元素初始化为1
```

哲学家i的结构

```c
do
{
    wait(chopstick[i]);
    wait(chopstick[(i+1)%5]);
    ...
    //ear for awhile
    ...
    signal(chopstick[i]);
    signal(chopstick[(i+1)%5]);
    ...
    //think for awhile
    ...
}while(true);
```

这一解决方案保证相邻的两个邻居不能同时进食，但是它可能导致死锁

死锁问题的可能的补救措施：

- 最多有4个哲学家同时坐在桌子上
- 只有一个哲学家的两根筷子都可用时，他才能拿起它们(必须在临界区内拿起两只筷子)
- 使用非对称解决方案。即单号的哲学家先拿起左边的筷子，接着右边的筷子

6.8节会给出哲学家就餐问题的一种解答。

### 6.8 管程





## 第七章 死锁

`死锁`(dead lock)一个被阻塞进程的集合，每个进程都持有一个资源并且等待请求一个被另一个集合中进程所持有的资源

`饥饿`(starvation)：一个进程等待一个持续可用的资源，但是该资源可能永远不会分配给这个等待的进程

### 7.1 系统模型

系统模型：

- 资源类型R1,R2,...,Rm
- 每种资源Ri有Wi个实例



进程只能按照如下顺序使用资源：

1. 申请：进程请求资源。如果申请不能立即被允许，那么申请进程应该等待，直到它能获得该资源为止。
2. 使用：进程对资源进行操作
3. 释放：进程释放资源



### 7.2 死锁特征

#### 7.2.1 必要条件

**互斥(mutual exclusion)**

至少有一个资源必须处于非共享模式，即一次只有一个进程可使用



**占有并等待(hold and wait)**

一个进程占有至少一个资源，并等待另一个资源，而该资源为其他进程所占有



**非抢占(no preemption)**

资源不能被抢占，即资源只能被进程在完成任务后资源释放



**循环等待 (circular wait)**

有一组等待进程{P0,...,Pn},P0等待的资源为P1占有，...,Pn等待的资源为P0占有



四个条件必须同时成立才会出现死锁



#### 7.2.2 资源分配图

资源分配图包括一个节点集合V和一个边集E

结点集合V可分成两种类型：

P={P1,P2,...,Pn} 为系统所有活动进程的集合

R={R1,R2,...,Rn} 为系统所有资源类型的集合

`申请边`:从进程Pi到资源类型Rj的有向边记作Pi->Rj,表示进程Pi已经申请了资源类型Rj的一个实例，并且正在等待这个资源

`分配边`:从资源类型Rj到进程Pi的有向边记为Rj->Pi，表示资源Rj的一个实例已经分配给了Pi



如果分配图没有环，那么系统就没有进程死锁



如果资源分配图有环，那么系统可能会也可能不会处于死锁状态



### 7.3 死锁处理方法

1. 死锁预防

通过协议来预防，确保系统不会进入死锁状态

2. 死锁避免

死锁可能发生，但是可以通过算法避免

适用于具有来自进程的可能资源请求的高级模型的操作系统

3. 检测并恢复

死锁可能会发生，但是有一些方法可以检测并恢复

在死锁发生频率很小的情况下，该方法更可取



### 7.4 死锁预防

发生死锁有4个必要条件，只需确保至少一个必要条件不成立，就能预防死锁发生

#### 7.4.1 互斥

可共享资源不要求互斥访问,但是有些资源本质就是互斥的，通常不能通过否定互斥条件来预防死锁



#### 7.4.2 持有并等待

保证当每个进程申请一个资源时，它不能占有其他资源

两种协议：

- 一个进程在其开始执行前申请并获得它所需要的全部资源
- 一个进程在申请其他资源前需要释放其所持有的全部资源



缺点：

- 资源利用率可能比较低，很多资源可能已分配，但是很长时间没有被使用
- 可能发生饥饿



#### 7.4.3 无抢占

如果一个进程持有资源并申请另一个不能立即分配的资源时，它现在分配的资源都可被抢占

两个协议：

1. 如果一个进程持有一些资源并且申请的其他资源不能被分配给它，那么它的所有资源都将被抢占
2. 当一个进程申请额外的资源，先看这些资源是否被一个在等待其他新资源的进程所持有。在这个情况下，第一个进程可以抢占第二个进程的资源

协议通常用于状态可以保存和恢复的资源，如CPU寄存器和内存。它们一般不适用于其他资源，如互斥锁和信号量

缺点：在没有死锁的情况下，一个进程所持有的资源也有可能被抢占

#### 7.4.4 循环等待

对所有资源类型进行完全排序，而且要求每个进程按递增顺序来申请资源

系统中的N种资源都是线性排序的

- 给每种资源在区间1到n内分配一个数字，叫做rank
- 同种资源rank相同
- 不同资源rank不同

要求进程按照严格的递增序列来申请资源



一个等价的策略是当进程请求一个特定级别的资源时，释放所有级别较高的资源



典型的排名顺序是基于自然使用。例如，由于存储设备是在打印机之前使用的，所以它们的级别较小



### 7.5 死锁避免

#### 7.5.1 安全状态

如果系统能按一定顺序为每个进程分配资源(不超过它的最大需求)，仍然避免死锁，那么系统的状态就是安全的



**安全序列**

进程序列<P1,P2,...,Pn>在当前分配状态下是安全序列是指：对于每个Pi,Pi仍可以申请的资源数小于当前可用资源加上所有进程Pj(其中j<i)所占有的资源。



如果系统中存在安全序列，那么系统是安全的，否则系统是不安全的。



所有死锁状态都是不安全的，但并非所有不安全状态都能导致死锁

![](image/%E6%AD%BB%E9%94%81%E4%B8%8E%E5%AE%89%E5%85%A8%E7%8A%B6%E6%80%81%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB.png)

#### 7.5.2 资源分配图算法

一个资源分配系统，它的每种资源类型只有一个实例

**需求边**

在资源分配图的基础上引入一种新的边

需求边Pi->Rj表示，进程Pi可能在未来的某个时刻申请资源Rj



- 当进程Pi申请资源Rj时，需求边变为申请边
- 当进程Pi释放资源Rj时，申请边变为需求边



保证进程的所有边都为需求边时，才能允许将需求便加入到图中



**资源分配图算法**

假设进程Pi申请资源Rj。只有在申请边Pi->Rj编程分配便Rj->Pi并且不会导致资源分配图形成环时，才能允许申请。环检测算法的时间复杂度是$n^2$数量级的

如果没有环存在，资源的分配会使得系统处于安全状态，否则，分配会导致系统处于非安全状态，此时进程需要等待资源申请



# 第三部分 内存管理

## 第八章 内存管理策略

### 8.1 背景

#### 8.1.1 基本硬件

CPU可以直接访问的通用存储只有内存和处理器内置的寄存器

程序必须(从磁盘)装入内存并放在一个进程中才能运行

CPU内置寄存器通常可以在一个CPU时钟周期内完成访问

对于内存的访问可能需要多个CPU时钟周期，在这种情况下，由于没有数据以便完成正在执行的指令，CPU通常需要暂停，内存访问频繁，这种情况通常是无法忍受的

补救措施：在CPU与内存之间，增加更快的内存，`高速缓冲`(cache)



`基地址寄存器`(base register)：含有最小的合法的物理内存地址

`界限地址寄存器`(limit register)：指定了范围的大小

通过这两个寄存器，我们能够确定一个进程可以访问的合法地址的范围；并且确保该进程只能访问这些合法地址

![](image/%E5%9F%BA%E5%9C%B0%E5%9D%80%E5%AF%84%E5%AD%98%E5%99%A8%E5%92%8C%E7%95%8C%E9%99%90%E5%9C%B0%E5%9D%80%E5%AF%84%E5%AD%98%E5%99%A8.png)

只有操作系统可以通过特殊的特权指令，才能加载基地址寄存器和界限地址寄存器

#### 8.1.2 地址绑定

`输入队列`(input queue)：在磁盘上等待调到内存以便执行的进程集合

通常，指令和数据绑定到存储器地址可在三个阶段发生

![](image/%E4%B8%80%E4%B8%AA%E7%94%A8%E6%88%B7%E7%A8%8B%E5%BA%8F%E7%9A%84%E5%A4%9A%E6%AD%A5%E9%AA%A4%E5%A4%84%E7%90%86.png)

- 编译时(compile time)：如果在编译时就知道进程在内存中的驻留地址，那么就可以生成绝对代码。如果将来开始地址发生变化，那么必须重新编译代码
- 加载时(load time)：如果在编译时不知道进程将驻留在何处，那么编译器就应生成`可重定位代码`(relocatable code)

- 执行时(runtime time)：如果进程在执行时可以从一个内存段移动到另一个内存段，那么绑定应该推迟到执行时才进行，采用这种方案需要特定硬件才行

#### 8.1.3 逻辑地址空间和物理地址空间

`逻辑地址`(logical address)：CPU生成的地址

`物理地址`(physical address)：内存单元看到的地址(即加载到内存地址寄存器MAR的地址)

编译时和加载时的地址绑定方法生成相同的逻辑地址和物理地址，而执行时绑定方案生成不同的逻辑地址和物理地址，在这种情况下，通常称逻辑地址为`虚拟地址`

`逻辑地址空间`(logical address space)：程序生成的所有逻辑地址的集合

`物理地址空间`(physical address space)：逻辑地址对应的所有物理地址的集合



`内存管理单元`(Memory-Management Unit,MMU)：完成虚拟地址到物理地址的运行时映射。



`重定位寄存器`(relocation register)：用户进程所生成的地址在送交内存之前，都将加上重定位寄存器的值



#### 8.1.4 动态加载

采用动态加载时，一个程序只有在调用时才会加载，所有程序都以重定位加载格式保存在磁盘上

优点：可以获得更好的内存空间利用率

动态加载不需要操作系统提供特别支持



#### 8.1.5 动态连接与共享库

`动态链接库`(dynamically linked library)：为系统库，可链接到用户程序

链接会延迟到运行时



动态链接时，每个库程序的引用都有一个`存根`(sub)，存根时一小段代码，用来之处如何定位适当的内存驻留库程序，或者在程序不在内存内时应该如何加载库



存根会用程序地址来替换自己，并开始执行程序，下次再执行该程序代码时，就可以直接进行，不会因动态链接产生任何开销



动态链接需要操作系统的帮助，只有操作系统才能检查程序是否再某个进程的内存空间内，或者时允许多个进程访问同样的内存地址



### 8.2 交换

进程可以暂时从内存交换到备份存储，当再次执行时再调回到内存中。

交换有可能让所有进程的总的物理地址空间超过真实系统的物理地址空间，增加系统的多道程序程度

![](image/%E4%B8%A4%E4%B8%AA%E8%BF%9B%E7%A8%8B%E7%9A%84%E4%BA%A4%E6%8D%A2.png)

#### 8.2.1 标准交换

标准交换再内存与备份存储之间移动进程。备份存储通常是快速磁盘

系统维护一个可运行的所有进程的就绪队列，它们的映像再备份存储或内存中。当CPU调度器决定要执行一个进程时，它调用分派器检查队列中的下一个进程是否再内存中，若不在并且没有空闲内存区域，那么分派器会换出当前位于内存中的一个进程，并换入所需经常。然后重新加载寄存器，并将控制权转移到所选进程

特点：

- 上下文切换时间相当高

假设用户进程大小100MB,并且备份存储是传输速度为50MB/s的标准硬盘。

则进程传入或传出内存的时间为2s

总的交换时间为4000ms+disktime

- 如果想换出一个进程，那么该进程应该是完全空闲的

I/O完成可能会将值存储在内存，该内存可能被新的进程占用

解决方法：

- 不能换出等待处理I/O的进程
- I/O操作的执行只能使用操作系统的缓冲，只有在进程换入时，操作系统缓冲与进程内存之间才能进行数据转移。（这种双缓冲本身增加了开销）



### 8.3 连续内存分配

内存通常分为两个区域：

- 操作系统通常与中断向量一起放在低内存
- 用户进程放在高内存

#### 8.3.1 内存保护

内存保护：防止进程访问不属于它的内存

重定位寄存器用于保护用户进程彼此不受影响，以及防止操作系统代码和数据发生变化

MMU通过动态地将逻辑地址加上重定位寄存器的值来进行映射。映射后的地址再发送内存

基地址寄存器：存放最小物理地址的值

界限寄存器：存放逻辑地址的范围

![](image/%E5%86%85%E5%AD%98%E4%BF%9D%E6%8A%A4.png)

#### 8.3.2 内存分配

**多分区方法**

将内存分为多个固定大小的分区，每个分区只可以包含一个进程。

**可变分区方案**

`孔(hole)`：一块可用内存

对于可变分区方案，操作系统有一个表，用于记录那些内存可用和哪些内存已用

随着进程进入系统，它们被加入输入队列。操作系统根据所有进程的内存需求和现有可用内存的情况，决定哪些进程可分配内存。当进程分配到空间时，它就加载到内存，并开始竞争CPU。进程终止时，它将释放内存。



**动态分配问题**

根据一组空闲的孔来分配大小为n的请求

- 首次适应(first-fit)：分配首个足够大的孔。查找可以从头开始，也可以从上次首次适应结束时开始
- 最优适应：分配最小的足够大的孔。应查找整个列表，除非列表按大小排序，这种方法可以产生最小剩余孔
- 最差适应：分配最大的孔

First-fit和 best-fit 在速度和存储利用率方面优于worst-fit

#### 8.3.3 碎片

`外部碎片(external fragmentation)`：总的内存之和可以满足请求，但内存并不连续

`内部碎片(internal fragmentation)`：进程所分配的内存可能比所需的要大，其差值称为内部碎片

**紧缩(compaction)**

一种解决外部碎片问题的方案，其目的是移动内存内容，以便将所有空闲空间合并称一整块。

如果重定位是静态的，并且在汇编或者加载时进行，那么就不能紧缩

如果重定位是动态的，并且在运行时进行，才能使用紧缩



### 8.4 分段（PPT上没有）

#### 8.4.1 基本方法

**分段segmentation**是一种支持用户视图的内存管理方案，逻辑地址空间是由一组段构成。每个段都有名称和长度。地址制定了段名称和段内偏移。因此用户通过两个量来指定地址：段名称和段偏移

段时编号的，通过段号来引用，逻辑地址由有序对<段号，偏移>组成

如一个C编译器可能会创建如下段

- 代码
- 全局变量
- 堆
- 每个线程使用的栈
- 标准的C库



#### 8.4.2 分段硬件

**段表segment table**

映射用户定义的二维地址到一维地址

段表的每个条目都有**段基地址segment base**和**段界限segment limit**

段基地址包含该段在内存中的开始物理地址，而段界限指定该段的长度



### 8.5 分页

#### 8.5.1 基本方法

`帧(页帧)frame`：将物理内存分为大小固定的块

`页(页面)page：`将逻辑内存也分为通用大小的块

`页表page table`：包含每页所在物理内存的基地址，通过页表可以将逻辑地址转换为物理地址

**地址转换**

CPU生成的每个地址可分为两部分：

- `页码page number`(p)：页表的索引
- `页偏移page offset`(d)：与基地址相组合形成物理内存地址

![](image/%E9%A1%B5%E7%A0%81%E4%B8%8E%E9%A1%B5%E5%81%8F%E7%A7%BB.png)
